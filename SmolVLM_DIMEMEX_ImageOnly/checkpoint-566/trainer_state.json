{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 566,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0353356890459364,
      "grad_norm": 11.898027420043945,
      "learning_rate": 0.00019681978798586573,
      "loss": 16.0586,
      "step": 10
    },
    {
      "epoch": 0.0706713780918728,
      "grad_norm": 2.8556137084960938,
      "learning_rate": 0.0001932862190812721,
      "loss": 4.7561,
      "step": 20
    },
    {
      "epoch": 0.10600706713780919,
      "grad_norm": 0.2723497152328491,
      "learning_rate": 0.00018975265017667846,
      "loss": 0.2806,
      "step": 30
    },
    {
      "epoch": 0.1413427561837456,
      "grad_norm": 0.16028577089309692,
      "learning_rate": 0.0001862190812720848,
      "loss": 0.0998,
      "step": 40
    },
    {
      "epoch": 0.17667844522968199,
      "grad_norm": 0.08035941421985626,
      "learning_rate": 0.00018268551236749118,
      "loss": 0.0563,
      "step": 50
    },
    {
      "epoch": 0.21201413427561838,
      "grad_norm": 0.04824516549706459,
      "learning_rate": 0.00017915194346289755,
      "loss": 0.0331,
      "step": 60
    },
    {
      "epoch": 0.24734982332155478,
      "grad_norm": 0.05659276619553566,
      "learning_rate": 0.0001756183745583039,
      "loss": 0.0257,
      "step": 70
    },
    {
      "epoch": 0.2826855123674912,
      "grad_norm": 0.03988947346806526,
      "learning_rate": 0.00017208480565371025,
      "loss": 0.0227,
      "step": 80
    },
    {
      "epoch": 0.31802120141342755,
      "grad_norm": 0.034853868186473846,
      "learning_rate": 0.00016855123674911661,
      "loss": 0.0209,
      "step": 90
    },
    {
      "epoch": 0.35335689045936397,
      "grad_norm": 0.024567872285842896,
      "learning_rate": 0.00016501766784452298,
      "loss": 0.0205,
      "step": 100
    },
    {
      "epoch": 0.38869257950530034,
      "grad_norm": 0.024507993832230568,
      "learning_rate": 0.00016148409893992932,
      "loss": 0.0197,
      "step": 110
    },
    {
      "epoch": 0.42402826855123676,
      "grad_norm": 0.03333927318453789,
      "learning_rate": 0.00015795053003533568,
      "loss": 0.0203,
      "step": 120
    },
    {
      "epoch": 0.45936395759717313,
      "grad_norm": 0.0299209151417017,
      "learning_rate": 0.00015441696113074207,
      "loss": 0.0187,
      "step": 130
    },
    {
      "epoch": 0.49469964664310956,
      "grad_norm": 0.019830696284770966,
      "learning_rate": 0.00015088339222614844,
      "loss": 0.0174,
      "step": 140
    },
    {
      "epoch": 0.5300353356890459,
      "grad_norm": 0.027460245415568352,
      "learning_rate": 0.00014734982332155477,
      "loss": 0.0175,
      "step": 150
    },
    {
      "epoch": 0.5653710247349824,
      "grad_norm": 0.06658095866441727,
      "learning_rate": 0.00014381625441696114,
      "loss": 0.0165,
      "step": 160
    },
    {
      "epoch": 0.6007067137809188,
      "grad_norm": 0.03773361071944237,
      "learning_rate": 0.0001402826855123675,
      "loss": 0.0163,
      "step": 170
    },
    {
      "epoch": 0.6360424028268551,
      "grad_norm": 0.02238175831735134,
      "learning_rate": 0.00013674911660777384,
      "loss": 0.0149,
      "step": 180
    },
    {
      "epoch": 0.6713780918727915,
      "grad_norm": 0.02808089554309845,
      "learning_rate": 0.0001332155477031802,
      "loss": 0.0148,
      "step": 190
    },
    {
      "epoch": 0.7067137809187279,
      "grad_norm": 0.022527888417243958,
      "learning_rate": 0.0001296819787985866,
      "loss": 0.0144,
      "step": 200
    },
    {
      "epoch": 0.7420494699646644,
      "grad_norm": 0.027382338419556618,
      "learning_rate": 0.00012614840989399296,
      "loss": 0.0147,
      "step": 210
    },
    {
      "epoch": 0.7773851590106007,
      "grad_norm": 0.028946561738848686,
      "learning_rate": 0.0001226148409893993,
      "loss": 0.0141,
      "step": 220
    },
    {
      "epoch": 0.8127208480565371,
      "grad_norm": 0.03515612706542015,
      "learning_rate": 0.00011908127208480566,
      "loss": 0.014,
      "step": 230
    },
    {
      "epoch": 0.8480565371024735,
      "grad_norm": 0.0233976598829031,
      "learning_rate": 0.00011554770318021201,
      "loss": 0.0132,
      "step": 240
    },
    {
      "epoch": 0.8833922261484098,
      "grad_norm": 0.028525374829769135,
      "learning_rate": 0.00011201413427561838,
      "loss": 0.013,
      "step": 250
    },
    {
      "epoch": 0.9187279151943463,
      "grad_norm": 0.02946486324071884,
      "learning_rate": 0.00010848056537102473,
      "loss": 0.0136,
      "step": 260
    },
    {
      "epoch": 0.9540636042402827,
      "grad_norm": 0.027830127626657486,
      "learning_rate": 0.00010494699646643109,
      "loss": 0.0128,
      "step": 270
    },
    {
      "epoch": 0.9893992932862191,
      "grad_norm": 0.02681470476090908,
      "learning_rate": 0.00010141342756183747,
      "loss": 0.0126,
      "step": 280
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.012336359359323978,
      "eval_runtime": 26.1341,
      "eval_samples_per_second": 12.321,
      "eval_steps_per_second": 0.804,
      "step": 283
    },
    {
      "epoch": 1.0247349823321554,
      "grad_norm": 0.04160076752305031,
      "learning_rate": 9.787985865724382e-05,
      "loss": 0.0123,
      "step": 290
    },
    {
      "epoch": 1.0600706713780919,
      "grad_norm": 0.0348472073674202,
      "learning_rate": 9.434628975265019e-05,
      "loss": 0.0126,
      "step": 300
    },
    {
      "epoch": 1.0954063604240283,
      "grad_norm": 0.10720076411962509,
      "learning_rate": 9.081272084805655e-05,
      "loss": 0.012,
      "step": 310
    },
    {
      "epoch": 1.1307420494699647,
      "grad_norm": 0.024660369381308556,
      "learning_rate": 8.72791519434629e-05,
      "loss": 0.0116,
      "step": 320
    },
    {
      "epoch": 1.1660777385159011,
      "grad_norm": 0.023105531930923462,
      "learning_rate": 8.374558303886925e-05,
      "loss": 0.0107,
      "step": 330
    },
    {
      "epoch": 1.2014134275618376,
      "grad_norm": 0.02475949190557003,
      "learning_rate": 8.021201413427563e-05,
      "loss": 0.0109,
      "step": 340
    },
    {
      "epoch": 1.2367491166077738,
      "grad_norm": 0.026985283941030502,
      "learning_rate": 7.667844522968198e-05,
      "loss": 0.0109,
      "step": 350
    },
    {
      "epoch": 1.2720848056537102,
      "grad_norm": 0.03586970642209053,
      "learning_rate": 7.314487632508834e-05,
      "loss": 0.0109,
      "step": 360
    },
    {
      "epoch": 1.3074204946996466,
      "grad_norm": 0.030162489041686058,
      "learning_rate": 6.96113074204947e-05,
      "loss": 0.0105,
      "step": 370
    },
    {
      "epoch": 1.342756183745583,
      "grad_norm": 0.02100573666393757,
      "learning_rate": 6.607773851590107e-05,
      "loss": 0.01,
      "step": 380
    },
    {
      "epoch": 1.3780918727915195,
      "grad_norm": 0.022232335060834885,
      "learning_rate": 6.254416961130742e-05,
      "loss": 0.0097,
      "step": 390
    },
    {
      "epoch": 1.4134275618374559,
      "grad_norm": 0.028645871207118034,
      "learning_rate": 5.901060070671378e-05,
      "loss": 0.01,
      "step": 400
    },
    {
      "epoch": 1.4487632508833923,
      "grad_norm": 0.02867811545729637,
      "learning_rate": 5.547703180212014e-05,
      "loss": 0.0095,
      "step": 410
    },
    {
      "epoch": 1.4840989399293285,
      "grad_norm": 0.02383711375296116,
      "learning_rate": 5.194346289752651e-05,
      "loss": 0.0092,
      "step": 420
    },
    {
      "epoch": 1.5194346289752652,
      "grad_norm": 0.023372560739517212,
      "learning_rate": 4.840989399293286e-05,
      "loss": 0.0092,
      "step": 430
    },
    {
      "epoch": 1.5547703180212014,
      "grad_norm": 0.02470025233924389,
      "learning_rate": 4.4876325088339225e-05,
      "loss": 0.0087,
      "step": 440
    },
    {
      "epoch": 1.5901060070671378,
      "grad_norm": 0.027741393074393272,
      "learning_rate": 4.134275618374558e-05,
      "loss": 0.0091,
      "step": 450
    },
    {
      "epoch": 1.6254416961130742,
      "grad_norm": 0.02901705913245678,
      "learning_rate": 3.780918727915195e-05,
      "loss": 0.0084,
      "step": 460
    },
    {
      "epoch": 1.6607773851590106,
      "grad_norm": 0.028488000854849815,
      "learning_rate": 3.4275618374558305e-05,
      "loss": 0.0086,
      "step": 470
    },
    {
      "epoch": 1.696113074204947,
      "grad_norm": 0.023207224905490875,
      "learning_rate": 3.074204946996467e-05,
      "loss": 0.0079,
      "step": 480
    },
    {
      "epoch": 1.7314487632508833,
      "grad_norm": 0.031819794327020645,
      "learning_rate": 2.7208480565371023e-05,
      "loss": 0.0076,
      "step": 490
    },
    {
      "epoch": 1.76678445229682,
      "grad_norm": 0.02555738389492035,
      "learning_rate": 2.3674911660777384e-05,
      "loss": 0.0077,
      "step": 500
    },
    {
      "epoch": 1.802120141342756,
      "grad_norm": 0.023862654343247414,
      "learning_rate": 2.0141342756183745e-05,
      "loss": 0.0073,
      "step": 510
    },
    {
      "epoch": 1.8374558303886925,
      "grad_norm": 0.027482742443680763,
      "learning_rate": 1.6607773851590106e-05,
      "loss": 0.0074,
      "step": 520
    },
    {
      "epoch": 1.872791519434629,
      "grad_norm": 0.02537057362496853,
      "learning_rate": 1.3074204946996469e-05,
      "loss": 0.0069,
      "step": 530
    },
    {
      "epoch": 1.9081272084805654,
      "grad_norm": 0.02395850047469139,
      "learning_rate": 9.540636042402827e-06,
      "loss": 0.0068,
      "step": 540
    },
    {
      "epoch": 1.9434628975265018,
      "grad_norm": 0.03102138638496399,
      "learning_rate": 6.007067137809187e-06,
      "loss": 0.007,
      "step": 550
    },
    {
      "epoch": 1.978798586572438,
      "grad_norm": 0.027488555759191513,
      "learning_rate": 2.473498233215548e-06,
      "loss": 0.0069,
      "step": 560
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0070314472541213036,
      "eval_runtime": 24.6172,
      "eval_samples_per_second": 13.08,
      "eval_steps_per_second": 0.853,
      "step": 566
    }
  ],
  "logging_steps": 10,
  "max_steps": 566,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7293982800056832.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
