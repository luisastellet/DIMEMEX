{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ============================================\n","# üß† GEMMA 3-12B ‚Äî FINE-TUNING COM IMAGENS\n","# ============================================"],"metadata":{"id":"P95TXYVjayYm"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hnUs-kcqj66Z","executionInfo":{"status":"ok","timestamp":1762204522913,"user_tz":180,"elapsed":1127,"user":{"displayName":"Luisa Muniz Stellet","userId":"17907239366073679393"}},"outputId":"e9d53e3a-0100-4c18-ffe9-81f1f49d4945"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/UFF/6_periodo/'Modelos de Linguagem Neurais'/DIMEMEX/\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JGud73DDlHn7","executionInfo":{"status":"ok","timestamp":1762204743782,"user_tz":180,"elapsed":110,"user":{"displayName":"Luisa Muniz Stellet","userId":"17907239366073679393"}},"outputId":"e3ec1686-2f4e-4bca-a80c-9baa6dc439f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dataset  LICENSE  notebooks  README.md\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/UFF/6_periodo/'Modelos de Linguagem Neurais'/DIMEMEX/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O0bTuT0pktcW","executionInfo":{"status":"ok","timestamp":1762204756494,"user_tz":180,"elapsed":4,"user":{"displayName":"Luisa Muniz Stellet","userId":"17907239366073679393"}},"outputId":"0f05135e-44b9-424a-a441-404100d959a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/UFF/6_periodo/Modelos de Linguagem Neurais/DIMEMEX\n"]}]},{"cell_type":"code","source":["from datasets import concatenate_datasets\n","import json\n","import pandas as pd\n","from datasets import Dataset\n","from pathlib import Path\n","\n","def load_split(split_name):\n","    img_dir = Path(split_name)\n","    with open(f\"{split_name}_data.json\", \"r\", encoding=\"utf-8\") as f:\n","        data = json.load(f)\n","    df = pd.DataFrame(data)\n","    df[\"label\"] = pd.read_csv(f\"{split_name}_labels.csv\").iloc[:, 0]\n","    df[\"image_path\"] = df[\"MEME-ID\"].apply(lambda x: str(img_dir / x))\n","    return Dataset.from_pandas(df)\n","\n","train_ds = load_split(\"train\")\n","val_ds = load_split(\"validation\")\n","test_ds = load_split(\"test\")\n","\n","dataset_dict = {\"train\": train_ds, \"validation\": val_ds, \"test\": test_ds}\n"],"metadata":{"id":"XSGg8BZBgFQB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================\n","# üõ†Ô∏è 1. Instalar depend√™ncias\n","# ============================================\n","!pip install -q transformers accelerate datasets peft bitsandbytes torch torchvision pillow tqdm scikit-learn matplotlib\n"],"metadata":{"id":"X-I3oZE7bOE0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762202470706,"user_tz":180,"elapsed":12822,"user":{"displayName":"Luisa Muniz Stellet","userId":"17907239366073679393"}},"outputId":"40c956de-b85a-4807-88f4-405ea0403e94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# ============================================\n","# üóÇÔ∏è 2. Upload dos dados\n","# ============================================\n","from google.colab import files\n","import zipfile, os\n","\n","print(\"üìÅ Envie o CSV (com colunas image_path,label)...\")\n","uploaded = files.upload()\n","csv_name = list(uploaded.keys())[0]\n","\n","print(\"\\nüì¶ Agora envie o ZIP com as imagens (ex: DIMEMEX_images.zip)...\")\n","uploaded2 = files.upload()\n","zip_name = list(uploaded2.keys())[0]\n","\n","os.makedirs(\"DIMEMEX_images\", exist_ok=True)\n","with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n","    zip_ref.extractall(\"DIMEMEX_images\")\n","\n","print(\"‚úÖ Arquivos carregados e extra√≠dos.\")"],"metadata":{"id":"lsHsUKCsbQo4","colab":{"base_uri":"https://localhost:8080/","height":404},"outputId":"56b63aef-abf1-4309-d642-6f7f2f7ae99d","executionInfo":{"status":"error","timestamp":1762203364627,"user_tz":180,"elapsed":0,"user":{"displayName":"Luisa Muniz Stellet","userId":"17907239366073679393"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["üìÅ Envie o CSV (com colunas image_path,label)...\n"]},{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-e3ddc1ee-2d58-4ae2-be18-0b82b3f1b449\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-e3ddc1ee-2d58-4ae2-be18-0b82b3f1b449\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"TypeError","evalue":"'NoneType' object is not subscriptable","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-193050150.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üìÅ Envie o CSV (com colunas image_path,label)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcsv_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"]}]},{"cell_type":"code","source":["# ============================================\n","# ‚öôÔ∏è 3. Configura√ß√£o e an√°lise do dataset\n","# ============================================"],"metadata":{"id":"SR_l_lvybdqP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","DATA_CSV = csv_name\n","IMAGE_ROOT = \"DIMEMEX_images\"\n","\n","df = pd.read_csv(DATA_CSV)\n","df[\"image_path\"] = df[\"image_path\"].apply(\n","    lambda p: os.path.join(IMAGE_ROOT, p) if not os.path.isabs(p) else p\n",")\n","df = df[df[\"image_path\"].apply(os.path.exists)].reset_index(drop=True)\n","\n","print(\"\\nüìä Tamanho total do dataset:\", len(df))\n","print(df[\"label\"].value_counts().rename_axis(\"Label\").reset_index(name=\"Quantidade\"))\n"],"metadata":{"id":"NR2f6LhwbgS8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================\n","# ‚öôÔ∏è 4. Configura√ß√µes principais\n","# ============================================"],"metadata":{"id":"yg_Xb8R836Ij"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from PIL import Image\n","from tqdm import tqdm\n","from datasets import Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","\n","from transformers import (\n","    AutoProcessor,\n","    AutoModelForCausalLM,\n","    TrainingArguments,\n","    Trainer,\n",")\n","from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","\n","MODEL_ID = \"HuggingFaceTB/SmolVLM-256M-Instruct\"\n","NUM_LABELS = 2\n","BATCH_SIZE = 2\n","EPOCHS = 2\n","LR = 2e-4\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"],"metadata":{"id":"vBfwlSzcbjwT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================\n","# üì¶ 5. Preparar datasets de treino, val e teste\n","# ============================================\n","# train_df, test_df = train_test_split(df, test_size=0.15, stratify=df[\"label\"], random_state=42)\n","# train_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df[\"label\"], random_state=42)\n","\n","ds_train = Dataset.from_pandas(train_df.reset_index(drop=True))\n","ds_val = Dataset.from_pandas(val_df.reset_index(drop=True))\n","ds_test = Dataset.from_pandas(test_df.reset_index(drop=True))\n","\n","print(f\"Treino: {len(ds_train)} | Valida√ß√£o: {len(ds_val)} | Teste: {len(ds_test)}\")"],"metadata":{"id":"6yA5dXUMb06y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================\n","# üß© 6. Processor e pr√©-processamento de imagem\n","# ============================================\n","from transformers import AutoProcessor\n","\n","processor = AutoProcessor.from_pretrained(MODEL_ID)\n","\n","def preprocess(examples):\n","    images = [Image.open(p).convert(\"RGB\") for p in examples[\"image_path\"]]\n","    inputs = processor(images=images, return_tensors=\"pt\")\n","    inputs[\"labels\"] = examples[\"label\"]\n","    return inputs\n","\n","ds_train = ds_train.map(preprocess, batched=True, remove_columns=ds_train.column_names)\n","ds_val = ds_val.map(preprocess, batched=True, remove_columns=ds_val.column_names)\n","ds_test = ds_test.map(preprocess, batched=True, remove_columns=ds_test.column_names)"],"metadata":{"id":"GxDcsLpmb2uH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================\n","# üß† 7. Modelo SmolVLM-256M-Instruct + LoRA\n","# ============================================\n","from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_ID,\n","    device_map=\"auto\",\n","    load_in_8bit=True,\n",")\n","\n","base_model = prepare_model_for_kbit_training(base_model)\n","\n","lora_cfg = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    lora_dropout=0.1,\n","    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n","    task_type=\"CAUSAL_LM\",\n",")\n","\n","model = get_peft_model(base_model, lora_cfg)\n","model.print_trainable_parameters()"],"metadata":{"id":"fBxeMZBRb9zb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================\n","# üìà 8. M√©tricas de avalia√ß√£o\n","# ============================================\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    preds = logits.argmax(-1)\n","    return {\n","        \"accuracy\": accuracy_score(labels, preds),\n","        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n","        \"precision\": precision_score(labels, preds, average=\"weighted\", zero_division=0),\n","        \"recall\": recall_score(labels, preds, average=\"weighted\", zero_division=0),\n","    }"],"metadata":{"id":"EhmYB02Bb_3Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================\n","# üßÆ 9. Configura√ß√µes de treino\n","# ============================================\n","training_args = TrainingArguments(\n","    output_dir=\"./SmolVLM_256M_Instruct_only_lora\",\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    num_train_epochs=EPOCHS,\n","    learning_rate=LR,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    fp16=True,\n","    load_best_model_at_end=True,\n","    logging_steps=50,\n","    save_total_limit=3,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=ds_train,\n","    eval_dataset=ds_val,\n","    tokenizer=processor,\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"id":"cW-dEY1mcCAR","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1762377877656,"user_tz":180,"elapsed":20,"user":{"displayName":"Luisa Muniz Stellet","userId":"17907239366073679393"}},"outputId":"ac7777a8-d10a-4f11-a871-bbc36e75729d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'TrainingArguments' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3869321601.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# üßÆ 9. Configura√ß√µes de treino\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ============================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./SmolVLM256M_Instructonly_lora\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'TrainingArguments' is not defined"]}]},{"cell_type":"code","source":["# ============================================\n","# üöÄ 10. Treinar modelo\n","# ============================================\n","trainer.train()"],"metadata":{"id":"LrWTx40ecDzg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================\n","# üìä 11. Diagn√≥stico ‚Äî Loss, Accuracy e F1\n","# ============================================\n","import matplotlib.pyplot as plt\n","import json\n","\n","log_file = os.path.join(training_args.output_dir, \"trainer_state.json\")\n","\n","if os.path.exists(log_file):\n","    with open(log_file, \"r\") as f:\n","        logs = json.load(f)\n","\n","    train_logs = logs.get(\"log_history\", [])\n","\n","    train_steps = [x[\"step\"] for x in train_logs if \"loss\" in x]\n","    train_loss = [x[\"loss\"] for x in train_logs if \"loss\" in x]\n","\n","    eval_steps = [x[\"step\"] for x in train_logs if \"eval_loss\" in x]\n","    eval_loss = [x[\"eval_loss\"] for x in train_logs if \"eval_loss\" in x]\n","    eval_acc = [x[\"eval_accuracy\"] for x in train_logs if \"eval_accuracy\" in x]\n","    eval_f1 = [x[\"eval_f1\"] for x in train_logs if \"eval_f1\" in x]\n","\n","    plt.figure(figsize=(8,4))\n","    plt.plot(train_steps, train_loss, label=\"Train Loss\")\n","    plt.plot(eval_steps, eval_loss, label=\"Eval Loss\")\n","    plt.title(\"Evolu√ß√£o da Loss por √âpoca\")\n","    plt.xlabel(\"Etapas (steps)\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend()\n","    plt.show()\n","\n","    plt.figure(figsize=(8,4))\n","    plt.plot(eval_steps, eval_acc, label=\"Accuracy\", marker='o')\n","    plt.plot(eval_steps, eval_f1, label=\"F1 Score\", marker='s')\n","    plt.title(\"Desempenho por √âpoca\")\n","    plt.xlabel(\"Etapas (steps)\")\n","    plt.ylabel(\"Pontua√ß√£o\")\n","    plt.legend()\n","    plt.show()\n","else:\n","    print(\"‚ö†Ô∏è Nenhum log encontrado. O treino pode n√£o ter sido salvo corretamente.\")"],"metadata":{"id":"T1WyVx0wcHQn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================\n","# ‚úÖ 12. Avalia√ß√£o final e resumo de m√©tricas\n","# ============================================\n","results = trainer.evaluate(ds_test)\n","print(\"\\nüìä Resultados finais no conjunto de teste:\")\n","for k, v in results.items():\n","    print(f\"{k:20s}: {v:.4f}\")"],"metadata":{"id":"5xdOzlcfcJuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ov-cUV_anV2"},"outputs":[],"source":["# ============================================\n","# üíæ 13. Salvar modelo final\n","# ============================================\n","model.save_pretrained(\"SmolVLM_256M_Instruct_only_lora\")\n","processor.save_pretrained(\"SmolVLM_256M_Instruct_only_lora\")\n","\n","print(\"\\n‚úÖ Fine-tuning conclu√≠do e pesos salvos em: SmolVLM_256M_Instruct_only_lora/\")\n"]}]}