{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79edfc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90209e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o inicial para o Google Colab\n",
    "!pip install -q torch accelerate transformers datasets evaluate scikit-learn\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# Verificar se h√° GPU dispon√≠vel e configurar para uso h√≠brido (GPU+CPU)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "accelerator = Accelerator(device_placement=True, mixed_precision=\"fp16\")\n",
    "print(f\"‚úÖ Dispositivo ativo: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad5b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install unbabel-comet\n",
    "! pip install evaluate tensorflow\n",
    "! pip install bert-score\n",
    "! pip install evaluate\n",
    "! pip install git+https://github.com/google-research/bleurt.git\n",
    "\n",
    "from bert_score import score\n",
    "from comet import download_model, load_from_checkpoint\n",
    "import evaluate\n",
    "import json\n",
    "import torch\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0390ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas(pasta, lote_salvamento=10):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    path = f\"/content/drive/MyDrive/DIMEMEX/{pasta}\"\n",
    "    arquivo_saida = f\"{path}/metricas.json\"\n",
    "\n",
    "    # === Carregar modelos uma √∫nica vez ===\n",
    "    print(\"üîÑ Carregando modelos...\")\n",
    "    bleurt = evaluate.load(\"bleurt\", \"bleurt-large-512\")\n",
    "    chrf = evaluate.load(\"chrf\")\n",
    "    bertscore = evaluate.load(\"bertscore\")\n",
    "    model_path = download_model(\"Unbabel/wmt22-cometkiwi-da\")\n",
    "    model = load_from_checkpoint(model_path)\n",
    "    print(\"‚úÖ Modelos carregados!\\n\")\n",
    "\n",
    "    # === Ler dados de entrada ===\n",
    "    with open(f'{path}/{pasta}_data_junto.json', 'r', encoding='utf-8') as file:\n",
    "        dados = json.load(file)\n",
    "\n",
    "    # === Se j√° existir arquivo parcial, continuar de onde parou ===\n",
    "    vetor = []\n",
    "    if os.path.exists(arquivo_saida):\n",
    "        with open(arquivo_saida, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                vetor = json.load(f)\n",
    "                print(f\"üìÇ Retomando: {len(vetor)} itens j√° processados.\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"‚ö†Ô∏è Arquivo de sa√≠da corrompido ‚Äî come√ßando do zero.\")\n",
    "                vetor = []\n",
    "\n",
    "    inicio = len(vetor)\n",
    "    total = len(dados)\n",
    "\n",
    "    # === Loop principal ===\n",
    "    for i, objeto in enumerate(dados[inicio:], inicio + 1):\n",
    "        result = objeto\n",
    "        result['metricas'] = {'text': {}, 'description': {}}\n",
    "\n",
    "        for termo in [\"text\", \"description\"]:\n",
    "            original = result['original'][termo]\n",
    "            traduzido = result['traduzido'][termo]\n",
    "\n",
    "            # BERTScore\n",
    "            result_bertscore = bertscore.compute(predictions=[traduzido],references=[original],model_type=\"xlm-roberta-large\",lang=\"pt\")\n",
    "\n",
    "            # BLEURT\n",
    "            result_bleurt = bleurt.compute(predictions=[traduzido], references=[original])\n",
    "\n",
    "            # COMET\n",
    "            data = [{\"src\": original, \"mt\": traduzido}]\n",
    "            result_comet = model.predict(data, batch_size=8, gpus=1)\n",
    "\n",
    "            # CHRF\n",
    "            result_chrf = chrf.compute(predictions=[traduzido], references=[original])\n",
    "\n",
    "            metricas = {\n",
    "                'bertscore': result_bertscore[\"f1\"][0],\n",
    "                'bleurt': result_bleurt['scores'][0],\n",
    "                'comet': result_comet['scores'][0],\n",
    "                'chrf': result_chrf['score']\n",
    "            }\n",
    "\n",
    "            result['metricas'][termo] = metricas\n",
    "\n",
    "        vetor.append(result)\n",
    "        print(f\"‚úÖ {i}/{total} processado ‚Äî {result['metricas']}\")\n",
    "\n",
    "        # === Salvar em lotes ===\n",
    "        if i % lote_salvamento == 0 or i == total:\n",
    "            with open(arquivo_saida, 'w', encoding='utf-8') as file:\n",
    "                json.dump(vetor, file, ensure_ascii=False, indent=4)\n",
    "            print(f\"üíæ Progresso salvo ({i}/{total})\")\n",
    "\n",
    "    print(f\"üìò Resultado salvo em: {arquivo_saida}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8fd868",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pasta in [\"test\", \"validation\", \"train\"]:\n",
    "    calcular_metricas(pasta)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
