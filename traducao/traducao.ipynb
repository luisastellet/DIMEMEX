{"cells":[{"cell_type":"markdown","metadata":{"id":"Aitg3gMVsmh0"},"source":["## C√≥digo para traduzir o dataset de espanhol para portugu√™s"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1207,"status":"ok","timestamp":1762712028417,"user":{"displayName":"Luisa Muniz Stellet","userId":"17907239366073679393"},"user_tz":180},"id":"c4rezxR4Vsoi","outputId":"e3f8f093-cd02-4974-dedd-ba89ae0bbb07"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from huggingface_hub import login\n","from google.colab import userdata\n","import transformers\n","import pandas as pd\n","import torch\n","import json\n","import gc\n","import os\n","from datasets import Dataset\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rKo8zjddlvRJ"},"outputs":[],"source":["def traduzir(pasta, batch_size=5):\n","\n","    # Definir o token!!!\n","    hf_token = userdata.get('HF_TOKEN')\n","    login(hf_token)\n","\n","    model_id = \"google/gemma-3-4b-it\"\n","\n","    # Ajeitar para o path correto!!!\n","    dataset_path = f\"/content/drive/MyDrive/UFF/6_periodo/Modelos de Linguagem Neurais/DIMEMEX/{pasta}\"\n","\n","    # Carregar dados diretamente do JSON\n","    with open(f\"{dataset_path}/{pasta}_data.json\", \"r\", encoding=\"utf-8\") as f:\n","        dados = json.load(f)\n","\n","    print(f\"üìä Carregados {len(dados)} exemplos da pasta {pasta}\")\n","\n","    # Configura√ß√£o do modelo\n","    tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\n","\n","    pipeline = transformers.pipeline(\n","        task=\"text-generation\",\n","        model=model_id,\n","        tokenizer=tokenizer,\n","        dtype=torch.bfloat16,\n","        device_map=\"auto\",\n","    )\n","\n","    # Path de sa√≠da\n","    json_output_path = f\"{dataset_path}/{pasta}_data_translated.json\"\n","\n","    anotacoes = []\n","\n","    # Processar os dados diretamente\n","    for i, objeto in enumerate(dados):\n","        print(f\"üîÑ Processando {i+1}/{len(dados)} - {objeto['MEME-ID']}\")\n","\n","        resultado = {\n","            \"MEME-ID\": objeto[\"MEME-ID\"],\n","            \"text\": objeto[\"text\"],\n","            \"description\": objeto[\"description\"]\n","        }\n","\n","        # Traduzir campos individualmente\n","        for campo in [\"text\", \"description\"]:\n","            if objeto[campo] and objeto[campo].strip():\n","                try:\n","                    prompt = f\"Somente traduza '{objeto[campo]}' do espanhol para o portugu√™s do Brasil, mantendo o mesmo n√≠vel de formalidade e estilo original.\"\n","\n","                    messages = [{\"role\": \"user\", \"content\": prompt}]\n","\n","                    outputs = pipeline(\n","                        messages,\n","                        max_new_tokens=256,\n","                        do_sample=True,\n","                        temperature=0.3,\n","                    )\n","\n","                    # Extrair a tradu√ß√£o corretamente\n","                    generated_text = outputs[0][\"generated_text\"][-1][\"content\"]\n","                    resultado[campo] = generated_text\n","                    print(f\"  ‚úÖ {campo} traduzido\")\n","\n","                except Exception as e:\n","                    print(f\"  ‚ùå Erro ao traduzir {campo}: {e}\")\n","                    resultado[campo] = objeto[campo]\n","\n","        anotacoes.append(resultado)\n","\n","        # Salvar progresso a cada 5 itens\n","        if (i + 1) % 5 == 0:\n","            with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n","                json.dump(anotacoes, f, ensure_ascii=False, indent=4)\n","            print(f\"-> Progresso salvo: {i+1}/{len(dados)}\")\n","\n","            # Limpar cache da GPU\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()\n","\n","    # Salvar resultado final\n","    with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(anotacoes, f, ensure_ascii=False, indent=4)\n","\n","    # Limpeza\n","    del pipeline\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    print(f\"‚úÖ Tradu√ß√£o conclu√≠da! {len(anotacoes)} itens processados.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5WVVIUhZX97D"},"outputs":[],"source":["for pasta in [\"train\"]:\n","    traduzir(pasta)\n","    print(f\"Pasta {pasta} est√° pronta!\")"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}